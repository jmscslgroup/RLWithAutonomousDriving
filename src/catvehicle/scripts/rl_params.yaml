catvehicle: #namespace

    running_step: 0.04 # amount of time the control will be executed
    pos_step: 0.016     # increment in position for each command
    
    #qlearn parameters
    alpha: 0.1
    gamma: 0.7
    epsilon: 0.9
    epsilon_discount: 0.999
    nepisodes: 500
    nsteps: 2000
    number_splits: 10 #set to change the number of state splits for the continuous problem and also the number of env_variable splits
    LEARNING_RATE: 0.001  #Hoang added parameter for Deep Q Learning
    MEMORY_SIZE: 1000000
    BATCH_SIZE: 20

    EXPLORATION_MAX: 1.0
    EXPLORATION_MIN: 0.01
    EXPLORATION_DECAY: 0.995

    running_step: 0.06 # Time for each step
    wait_time: 0.1 # Time to wait in the reset phases

    n_actions: 3 # We have 3 actions, Forwards,TurnLeft,TurnRight,Backwards
    n_observations: 2 # We have 2 different observations; dist and angle

    speed_step: 1.0 # Time to wait in the reset phases

    linear_forward_speed: 2.0 # Spwwed for ging fowards
    linear_turn_speed: 2.0 # Lienare speed when turning
    angular_speed: 0.3 # Angular speed when turning Left or Right
    init_linear_forward_speed: 0.0 # Initial linear speed in which we start each episode
    init_linear_turn_speed: 0.0 # Initial angular speed in shich we start each episode
    
    new_ranges: 5 # How many laser readings we jump in each observation reading, the bigger the less laser resolution
    min_range: 5 # Minimum meters below wich we consider we have crashed
    max_sensor_value: 80 # Value considered Ok, no wall
    min_sensor_value: -2 # Value considered there is an obstacle or crashed; considers angle too
    
    min_angle_value: -0.79
    max_angle_value: 0.79
    
    desired_pose:
      x: 0.0
      y: 0.0
      z: 0.0

    complete_reward: 1500 # Very large to counteract end_epsidoe_points
    path_epislon: 1.5  # How close the car must be to get path reward
    path_reward: 200.0  # Reward car gets for being path_epsilon-close to a point on the path.
    forwards_reward: 2 # Points Given to go forwards
    turn_reward: 1 # Points Given to turn as action
    end_episode_points: 1000 # Points given when ending an episode
    

